<!-- Plugin Configuration File. Read more: https://plugins.jetbrains.com/docs/intellij/plugin-configuration-file.html -->
<idea-plugin>
    <!-- Unique identifier of the plugin. It should be FQN. It cannot be changed between the plugin versions. -->
    <id>fr.baretto.OllamAssist</id>

    <!-- Public plugin name should be written in Title Case.
         Guidelines: https://plugins.jetbrains.com/docs/marketplace/plugin-overview-page.html#plugin-name -->
    <name>OllamAssist</name>


    <!-- A displayed Vendor name or Organization ID displayed on the Plugins Page. -->
    <vendor email="contact@baretto.fr" url="https://www.baretto.fr">Baretto</vendor>

    <!-- Description of the plugin displayed on the Plugin Page and IDE Plugin Manager.
         Simple HTML elements (text formatting, paragraphs, and lists) can be added inside of <![CDATA[ ]]> tag.
         Guidelines: https://plugins.jetbrains.com/docs/marketplace/plugin-overview-page.html#plugin-description -->
    <description><![CDATA[
<div>
    <h2>OllamAssist Plugin for IntelliJ IDEA</h2>
    <p>OllamAssist is a plugin designed to integrate seamlessly with IntelliJ IDEA, leveraging the power of <strong>Ollama</strong> to enhance developer productivity.
     This intelligent assistant offers conversational interactions with your code, insightful discussions, and smart code autocompletion, making it your ultimate coding companion.
     <strong>All processing is done locally</strong>, ensuring maximum privacy and allowing you to work without an internet connection.</p>

    <h3>Key Features</h3>
    <ul>
        <li><strong>In-IDE Chat with Ollama Models:</strong> Engage directly with AI for insights and explanations, all within your JetBrains IDE. The model has access to your project's indexed sources via <strong>RAG (Retrieval-Augmented Generation)</strong>, enabling context-aware responses based on your codebase.</li>
        <li><strong>Enhanced Context Awareness:</strong> Boost model accuracy by providing your workspace for tailored suggestions.</li>
        <li><strong>Generate commit message:</strong> OllamAssist can generate a commit message based on the current git diff, following the Conventional Commits specification..</li>
        <li><strong>Offline Mode:</strong> Enjoy full functionality offline after loading the model and data.</li>

        <li><strong>Experimental Smart Code Autocomplete:</strong> Anticipates your next steps in coding, offering intelligent suggestions when pressing <strong>Shift+Space</strong>.
            <ul>
                <li>Press <strong>Enter</strong> to insert the suggested code.</li>
                <li>Press any other key to dismiss the suggestion.</li>
            </ul>
        </li>
    </ul>

    <h3>Customizable Model Settings</h3>
    <p>Developers can choose the AI model to be used via the plugin's <strong>Settings</strong> page, ensuring flexibility and alignment with their specific requirements.</p>

    <h3>Minimum Requirements</h3>
    <p>For the latest system requirements, please refer to the <a href="https://ollama.com/download#requirements" target="_blank">official Ollama requirements page</a>.</p>

    <h3>Get Started in 5 Minutes</h3>
    <ol>
        <li>Download and start <a href="https://ollama.com/download">Ollama</a>.</li>
        <li>Open a terminal and download a model using the command: <code>ollama run llama3.1</code>.</li>
        <li>Start IntelliJ IDEA, go to <strong>Plugins > Marketplace</strong>, and search for "OllamAssist".</li>
        <li>Install the "OllamAssist" plugin.</li>
        <li>In the OllamAssist settings window, select the Ollama model if it isn't already set to <code>llama3.1</code>.</li>
        <li>Start coding with your smart OllamAssist!</li>
    </ol>
</div>

  ]]></description>

    <change-notes><![CDATA[
        <h2>V1.2.0</h2>
        <UL>
            <LI>feat: Generate commit message.</LI>
        </UL>
        <h2>V1.1.3</h2>
        <UL>
            <LI>fix: Reload model after new model selection.</LI>
        </UL>
        <h2>V1.1.2</h2>
        <UL>
            <LI>fix/issue-77: Filter documents based on the score during RAG retrieval.</LI>
        </UL>
        <h2>V1.1.1</h2>
        <UL>
            <LI>fix: Fix for the disappearance of the prerequisites panel when the models are not loaded.</LI>
            <LI>fix: Add missing dependencies for some jetbrains product</LI>
        </UL>
        <h2>V1.1.0</h2>
        <UL>
            <LI>feat/issue-58: Users can set the limit for indexed documents</LI>
            <LI>feat/issue-49: Users can choose the embedding model from the settings panel</LI>
            <LI>feat: Users can choose the chat model directly from prompt panel</LI>
            <LI>feat: Users can choose select code and click to the gutter icon in order to start a chat</LI>
            <LI>chore: Replace delete icon</LI>
        </UL>
        <UL>
            <LI>feat/issue-26: Start chat by a code selection</LI>
        </UL>
        <h2>V1.0.6</h2>
        <UL>
            <LI>fix/issue-49: Reduce CPU usage during indexation</LI>
        </UL>
        <h2>V1.0.5</h2>
        <UL>
            <LI>feat/issue-38: Configure OllamAssist for all jetbrains products</LI>
            <LI>feat: Ollama url are configurable in settings panel</LI>
            <LI>feat: Fetch available models and autocomplete in configuration dialog</LI>
            <LI>feat: Suppress displaying more tokens from a canceled request </LI>
            <LI>feat: Distinguish completed, canceled and erroneous (e.g. timed-out) requests with different icons and add informational tooltips </LI>
            <LI>fix: Add horizontal scrollbar (when necessary) to code output (SyntaxHighlighterPanel)</>
            <LI>fix/issue-33: Fix loading panel during OllamAssist starting</LI>
        </UL>
        <h2>V1.0.4</h2>
        <UL>
            <LI>feat/issue-31: Add filter for incremental indexation</LI>
            <LI>feat/issue-27: Check prerequisites before execute plugin</LI>
            <LI>fix/issue-25: Replace french words by icons and tooltips</LI>
            <LI>fix/issue-24: improve UI</LI>
        </UL>
       <h2>V1.0.3</h2>
        <UL>
            <LI>fix/issue-12: Add icon for light theme</LI>
            <LI>fix/issue-15: Add scrollbar if textarea is not enough for showing prompt</LI>
            <LI>feat/issue-12: Clean history and start conversation from zero</LI>
            <LI>feat/issue-9: Refactor indexation and RAG configuration</LI>
        </UL>
        <h2>V1.0.2</h2>
        <UL>
            <LI>Fix: fix chat scrollbar</LI>
        </UL>
        <h2>V1.0.1</h2>
        <UL>
            <LI>Fix: fix chat scrollbar</LI>
        </UL>
        <h2>V1.0.O</h2>
        <UL>
            <LI>Initial release</LI>
        </UL>
    ]]></change-notes>
    <!-- Product and plugin compatibility requirements.
         Read more: https://plugins.jetbrains.com/docs/intellij/plugin-compatibility.html -->
    <depends>com.intellij.modules.platform</depends>
    <depends>com.intellij.modules.lang</depends>

    <!-- Extension points defined by the plugin.
         Read more: https://plugins.jetbrains.com/docs/intellij/plugin-extension-points.html -->
    <extensions defaultExtensionNs="com.intellij">
        <toolWindow id="OllamAssist"
                    anchor="right"
                    icon="/icons/icon.svg"
                    factoryClass="fr.baretto.ollamassist.chat.ui.OllamaWindowFactory"/>
        <applicationService serviceImplementation="fr.baretto.ollamassist.prerequiste.PrerequisiteService"/>
        <applicationService serviceImplementation="fr.baretto.ollamassist.setting.OllamAssistSettings"/>

        <applicationService serviceImplementation="fr.baretto.ollamassist.chat.rag.IndexRegistry"/>
        <projectService serviceImplementation="fr.baretto.ollamassist.chat.rag.DocumentIngestFactory"/>
        <projectService serviceImplementation="fr.baretto.ollamassist.chat.rag.LuceneEmbeddingStore"/>
        <projectService serviceImplementation="fr.baretto.ollamassist.chat.rag.FilesUtil"/>
        <projectService serviceImplementation="fr.baretto.ollamassist.chat.rag.DocumentIndexingPipeline"/>
        <projectService serviceImplementation="fr.baretto.ollamassist.chat.service.OllamaService"/>


        <projectService serviceImplementation="fr.baretto.ollamassist.chat.askfromcode.SelectionGutterIcon"/>
        <projectService serviceImplementation="fr.baretto.ollamassist.chat.askfromcode.OverlayPromptPanelFactory"/>


        <projectConfigurable instance="fr.baretto.ollamassist.setting.OllamassistSettingsConfigurable" displayName="OllamAssist"/>


        <postStartupActivity implementation="fr.baretto.ollamassist.OllamAssistStartup">Ollamassist startup</postStartupActivity>

        <notificationGroup id="RAG_Indexation" displayType="BALLOON"/>
        <notificationGroup id="index_corrupted" displayType="BALLOON"/>
     </extensions>

    <actions>
        <action id="fr.baretto.ollamassist.MyAutoCompletionAction"
                class="fr.baretto.ollamassist.completion.InlineCompletionAction"
                text="Trigger AI Autocompletion"
                description="Triggers AI-based autocompletion for code.">
            <add-to-group group-id="EditorActions" anchor="last"/>
            <keyboard-shortcut keymap="$default" first-keystroke="shift SPACE"/>
        </action>
        <action id="AddTestsCommitMessageAction"
                class="fr.baretto.ollamassist.git.CommitMessageGenerator"
                text="Write commit Message"
                description="Generate commit message with OllamAssist">
            <add-to-group group-id="Vcs.MessageActionGroup" anchor="last"/>
        </action>
    </actions>
</idea-plugin>